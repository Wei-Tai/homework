{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Fundamentals of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Generalization: The goal of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Underfitting and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Noisy training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Ambiguous features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rare features and spurious correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding white-noise channels or all-zeros channels to MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "train_images_with_noise_channels = np.concatenate(\n",
    "    [train_images, np.random.random((len(train_images), 784))], axis=1)\n",
    "\n",
    "train_images_with_zeros_channels = np.concatenate(\n",
    "    [train_images, np.zeros((len(train_images), 784))], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training the same model on MNIST data with noise channels or all-zero channels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 0.6081 - accuracy: 0.8120 - val_loss: 0.4010 - val_accuracy: 0.8680\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2433 - accuracy: 0.9250 - val_loss: 0.2432 - val_accuracy: 0.9233\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1589 - accuracy: 0.9509 - val_loss: 0.2175 - val_accuracy: 0.9352\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1140 - accuracy: 0.9646 - val_loss: 0.1357 - val_accuracy: 0.9613\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0845 - accuracy: 0.9735 - val_loss: 0.1359 - val_accuracy: 0.9612\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0636 - accuracy: 0.9793 - val_loss: 0.1258 - val_accuracy: 0.9647\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0468 - accuracy: 0.9846 - val_loss: 0.1218 - val_accuracy: 0.9678\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0340 - accuracy: 0.9891 - val_loss: 0.1859 - val_accuracy: 0.9551\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0267 - accuracy: 0.9910 - val_loss: 0.1247 - val_accuracy: 0.9694\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.1364 - val_accuracy: 0.9699\n",
      "Epoch 1/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.2874 - accuracy: 0.9160 - val_loss: 0.1594 - val_accuracy: 0.9558\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.1179 - accuracy: 0.9657 - val_loss: 0.1037 - val_accuracy: 0.9679\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0788 - accuracy: 0.9772 - val_loss: 0.0854 - val_accuracy: 0.9740\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0554 - accuracy: 0.9830 - val_loss: 0.0833 - val_accuracy: 0.9762\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0421 - accuracy: 0.9879 - val_loss: 0.0896 - val_accuracy: 0.9741\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0314 - accuracy: 0.9910 - val_loss: 0.0850 - val_accuracy: 0.9772\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 0.0814 - val_accuracy: 0.9780\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.0858 - val_accuracy: 0.9783\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.0825 - val_accuracy: 0.9807\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 0.0103 - accuracy: 0.9971 - val_loss: 0.0909 - val_accuracy: 0.9789\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "history_noise = model.fit(\n",
    "    train_images_with_noise_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)\n",
    "\n",
    "model = get_model()\n",
    "history_zeros = model.fit(\n",
    "    train_images_with_zeros_channels, train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Plotting a validation accuracy comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2abf7730fd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_acc_noise = history_noise.history[\"val_accuracy\"]\n",
    "val_acc_zeros = history_zeros.history[\"val_accuracy\"]\n",
    "epochs = range(1, 11)\n",
    "plt.plot(epochs, val_acc_noise, \"b-\",\n",
    "         label=\"Validation accuracy with noise channels\")\n",
    "plt.plot(epochs, val_acc_zeros, \"b--\",\n",
    "         label=\"Validation accuracy with zeros channels\")\n",
    "plt.title(\"Effect of noise channels on validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The nature of generalization in deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Fitting a MNIST model with randomly shuffled labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3174 - accuracy: 0.1043 - val_loss: 2.3063 - val_accuracy: 0.1030\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3005 - accuracy: 0.1158 - val_loss: 2.3147 - val_accuracy: 0.0984\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2899 - accuracy: 0.1279 - val_loss: 2.3215 - val_accuracy: 0.1023\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2758 - accuracy: 0.1418 - val_loss: 2.3344 - val_accuracy: 0.0988\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2581 - accuracy: 0.1570 - val_loss: 2.3429 - val_accuracy: 0.0958\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2367 - accuracy: 0.1689 - val_loss: 2.3565 - val_accuracy: 0.1022\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2107 - accuracy: 0.1855 - val_loss: 2.3710 - val_accuracy: 0.0967\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.1821 - accuracy: 0.2019 - val_loss: 2.3951 - val_accuracy: 0.0949\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.1522 - accuracy: 0.2162 - val_loss: 2.4238 - val_accuracy: 0.0964\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.1197 - accuracy: 0.2340 - val_loss: 2.4403 - val_accuracy: 0.0943\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.0851 - accuracy: 0.2494 - val_loss: 2.4692 - val_accuracy: 0.1016\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.0506 - accuracy: 0.2664 - val_loss: 2.4931 - val_accuracy: 0.1010\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.0138 - accuracy: 0.2836 - val_loss: 2.5190 - val_accuracy: 0.1003\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.9767 - accuracy: 0.2998 - val_loss: 2.5521 - val_accuracy: 0.0968\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.9442 - accuracy: 0.3144 - val_loss: 2.5830 - val_accuracy: 0.0938\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.9061 - accuracy: 0.3295 - val_loss: 2.6238 - val_accuracy: 0.0955\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.8701 - accuracy: 0.3446 - val_loss: 2.6640 - val_accuracy: 0.0944\n",
      "Epoch 18/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.8370 - accuracy: 0.3559 - val_loss: 2.6759 - val_accuracy: 0.0966\n",
      "Epoch 19/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.8025 - accuracy: 0.3708 - val_loss: 2.7309 - val_accuracy: 0.0971\n",
      "Epoch 20/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.7672 - accuracy: 0.3835 - val_loss: 2.7519 - val_accuracy: 0.0978\n",
      "Epoch 21/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.7358 - accuracy: 0.4001 - val_loss: 2.8063 - val_accuracy: 0.0977\n",
      "Epoch 22/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.7037 - accuracy: 0.4101 - val_loss: 2.8458 - val_accuracy: 0.0960\n",
      "Epoch 23/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.6699 - accuracy: 0.4220 - val_loss: 2.8933 - val_accuracy: 0.0980\n",
      "Epoch 24/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.6419 - accuracy: 0.4313 - val_loss: 2.9197 - val_accuracy: 0.0970\n",
      "Epoch 25/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.6094 - accuracy: 0.4456 - val_loss: 2.9545 - val_accuracy: 0.0993\n",
      "Epoch 26/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.5794 - accuracy: 0.4559 - val_loss: 3.0239 - val_accuracy: 0.0964\n",
      "Epoch 27/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.5512 - accuracy: 0.4669 - val_loss: 3.0558 - val_accuracy: 0.0972\n",
      "Epoch 28/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.5235 - accuracy: 0.4752 - val_loss: 3.1080 - val_accuracy: 0.0962\n",
      "Epoch 29/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.4960 - accuracy: 0.4877 - val_loss: 3.1411 - val_accuracy: 0.0978\n",
      "Epoch 30/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.4697 - accuracy: 0.4978 - val_loss: 3.2053 - val_accuracy: 0.0999\n",
      "Epoch 31/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.4420 - accuracy: 0.5079 - val_loss: 3.2674 - val_accuracy: 0.0932\n",
      "Epoch 32/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.4171 - accuracy: 0.5171 - val_loss: 3.2888 - val_accuracy: 0.0961\n",
      "Epoch 33/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3921 - accuracy: 0.5255 - val_loss: 3.3358 - val_accuracy: 0.0973\n",
      "Epoch 34/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3684 - accuracy: 0.5337 - val_loss: 3.3911 - val_accuracy: 0.0972\n",
      "Epoch 35/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3464 - accuracy: 0.5421 - val_loss: 3.4591 - val_accuracy: 0.0957\n",
      "Epoch 36/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.3218 - accuracy: 0.5496 - val_loss: 3.4830 - val_accuracy: 0.0972\n",
      "Epoch 37/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2964 - accuracy: 0.5603 - val_loss: 3.5451 - val_accuracy: 0.0977\n",
      "Epoch 38/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2757 - accuracy: 0.5653 - val_loss: 3.6017 - val_accuracy: 0.0994\n",
      "Epoch 39/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2539 - accuracy: 0.5754 - val_loss: 3.6518 - val_accuracy: 0.0981\n",
      "Epoch 40/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2313 - accuracy: 0.5839 - val_loss: 3.7052 - val_accuracy: 0.0998\n",
      "Epoch 41/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.2126 - accuracy: 0.5900 - val_loss: 3.7751 - val_accuracy: 0.0977\n",
      "Epoch 42/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1922 - accuracy: 0.5969 - val_loss: 3.8002 - val_accuracy: 0.0972\n",
      "Epoch 43/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1702 - accuracy: 0.6054 - val_loss: 3.8710 - val_accuracy: 0.0996\n",
      "Epoch 44/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1509 - accuracy: 0.6122 - val_loss: 3.9047 - val_accuracy: 0.0987\n",
      "Epoch 45/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1336 - accuracy: 0.6200 - val_loss: 3.9865 - val_accuracy: 0.0937\n",
      "Epoch 46/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.1157 - accuracy: 0.6245 - val_loss: 4.0368 - val_accuracy: 0.0964\n",
      "Epoch 47/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0955 - accuracy: 0.6309 - val_loss: 4.0789 - val_accuracy: 0.0947\n",
      "Epoch 48/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0778 - accuracy: 0.6379 - val_loss: 4.1680 - val_accuracy: 0.0963\n",
      "Epoch 49/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0611 - accuracy: 0.6440 - val_loss: 4.2055 - val_accuracy: 0.0966\n",
      "Epoch 50/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0431 - accuracy: 0.6509 - val_loss: 4.2573 - val_accuracy: 0.0954\n",
      "Epoch 51/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0272 - accuracy: 0.6579 - val_loss: 4.3177 - val_accuracy: 0.0963\n",
      "Epoch 52/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 1.0098 - accuracy: 0.6629 - val_loss: 4.3525 - val_accuracy: 0.0964\n",
      "Epoch 53/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9947 - accuracy: 0.6690 - val_loss: 4.4323 - val_accuracy: 0.0955\n",
      "Epoch 54/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9776 - accuracy: 0.6739 - val_loss: 4.4941 - val_accuracy: 0.0951\n",
      "Epoch 55/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9627 - accuracy: 0.6804 - val_loss: 4.5530 - val_accuracy: 0.0978\n",
      "Epoch 56/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9472 - accuracy: 0.6858 - val_loss: 4.5768 - val_accuracy: 0.0967\n",
      "Epoch 57/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9328 - accuracy: 0.6909 - val_loss: 4.6886 - val_accuracy: 0.0957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9179 - accuracy: 0.6948 - val_loss: 4.7267 - val_accuracy: 0.0977\n",
      "Epoch 59/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.9025 - accuracy: 0.6995 - val_loss: 4.7702 - val_accuracy: 0.0972\n",
      "Epoch 60/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8887 - accuracy: 0.7053 - val_loss: 4.8700 - val_accuracy: 0.0964\n",
      "Epoch 61/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8757 - accuracy: 0.7088 - val_loss: 4.8773 - val_accuracy: 0.0978\n",
      "Epoch 62/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8608 - accuracy: 0.7165 - val_loss: 4.9650 - val_accuracy: 0.0952\n",
      "Epoch 63/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8460 - accuracy: 0.7191 - val_loss: 5.0422 - val_accuracy: 0.0970\n",
      "Epoch 64/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8320 - accuracy: 0.7259 - val_loss: 5.1047 - val_accuracy: 0.0986\n",
      "Epoch 65/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8211 - accuracy: 0.7269 - val_loss: 5.1503 - val_accuracy: 0.0974\n",
      "Epoch 66/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.8081 - accuracy: 0.7333 - val_loss: 5.1992 - val_accuracy: 0.0971\n",
      "Epoch 67/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7953 - accuracy: 0.7366 - val_loss: 5.2770 - val_accuracy: 0.0967\n",
      "Epoch 68/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7838 - accuracy: 0.7411 - val_loss: 5.3162 - val_accuracy: 0.0962\n",
      "Epoch 69/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7682 - accuracy: 0.7456 - val_loss: 5.4095 - val_accuracy: 0.0978\n",
      "Epoch 70/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7580 - accuracy: 0.7503 - val_loss: 5.4661 - val_accuracy: 0.0972\n",
      "Epoch 71/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7466 - accuracy: 0.7546 - val_loss: 5.5228 - val_accuracy: 0.0990\n",
      "Epoch 72/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7349 - accuracy: 0.7599 - val_loss: 5.6002 - val_accuracy: 0.0974\n",
      "Epoch 73/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7232 - accuracy: 0.7641 - val_loss: 5.6244 - val_accuracy: 0.0995\n",
      "Epoch 74/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.7104 - accuracy: 0.7674 - val_loss: 5.7369 - val_accuracy: 0.1009\n",
      "Epoch 75/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6999 - accuracy: 0.7706 - val_loss: 5.8162 - val_accuracy: 0.0968\n",
      "Epoch 76/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6893 - accuracy: 0.7736 - val_loss: 5.8738 - val_accuracy: 0.1000\n",
      "Epoch 77/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6801 - accuracy: 0.7780 - val_loss: 5.9123 - val_accuracy: 0.0955\n",
      "Epoch 78/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6704 - accuracy: 0.7817 - val_loss: 6.0074 - val_accuracy: 0.0990\n",
      "Epoch 79/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6590 - accuracy: 0.7844 - val_loss: 6.0624 - val_accuracy: 0.0988\n",
      "Epoch 80/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6508 - accuracy: 0.7883 - val_loss: 6.1397 - val_accuracy: 0.0996\n",
      "Epoch 81/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6398 - accuracy: 0.7923 - val_loss: 6.1862 - val_accuracy: 0.0974\n",
      "Epoch 82/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6295 - accuracy: 0.7944 - val_loss: 6.2697 - val_accuracy: 0.0981\n",
      "Epoch 83/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6206 - accuracy: 0.7982 - val_loss: 6.3468 - val_accuracy: 0.1046\n",
      "Epoch 84/100\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.6110 - accuracy: 0.8022 - val_loss: 6.4001 - val_accuracy: 0.0967\n",
      "Epoch 85/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.6022 - accuracy: 0.8047 - val_loss: 6.4465 - val_accuracy: 0.0987\n",
      "Epoch 86/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5906 - accuracy: 0.8082 - val_loss: 6.6059 - val_accuracy: 0.0982\n",
      "Epoch 87/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5856 - accuracy: 0.8096 - val_loss: 6.5838 - val_accuracy: 0.0977\n",
      "Epoch 88/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5760 - accuracy: 0.8143 - val_loss: 6.6723 - val_accuracy: 0.1024\n",
      "Epoch 89/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5651 - accuracy: 0.8180 - val_loss: 6.7506 - val_accuracy: 0.0973\n",
      "Epoch 90/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5582 - accuracy: 0.8206 - val_loss: 6.7961 - val_accuracy: 0.0979\n",
      "Epoch 91/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5504 - accuracy: 0.8225 - val_loss: 6.8564 - val_accuracy: 0.0967\n",
      "Epoch 92/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5413 - accuracy: 0.8256 - val_loss: 6.9896 - val_accuracy: 0.0972\n",
      "Epoch 93/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5349 - accuracy: 0.8271 - val_loss: 7.0231 - val_accuracy: 0.0993\n",
      "Epoch 94/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5264 - accuracy: 0.8319 - val_loss: 7.0975 - val_accuracy: 0.0990\n",
      "Epoch 95/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5180 - accuracy: 0.8331 - val_loss: 7.1619 - val_accuracy: 0.0946\n",
      "Epoch 96/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5111 - accuracy: 0.8371 - val_loss: 7.2985 - val_accuracy: 0.0964\n",
      "Epoch 97/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.5017 - accuracy: 0.8390 - val_loss: 7.3012 - val_accuracy: 0.1009\n",
      "Epoch 98/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4953 - accuracy: 0.8429 - val_loss: 7.4195 - val_accuracy: 0.0984\n",
      "Epoch 99/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4877 - accuracy: 0.8456 - val_loss: 7.4507 - val_accuracy: 0.0969\n",
      "Epoch 100/100\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.4799 - accuracy: 0.8464 - val_loss: 7.4978 - val_accuracy: 0.0982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2abf7ebf790>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "random_train_labels = train_labels[:]\n",
    "np.random.shuffle(random_train_labels)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, random_train_labels,\n",
    "          epochs=100,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The manifold hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Interpolation as a source of generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Why deep learning works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training data is paramount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Evaluating machine-learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training, validation, and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Simple hold-out validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### K-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Iterated K-fold validation with shuffling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Beating a common-sense baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Things to keep in mind about model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Improving model fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Tuning key gradient descent parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a MNIST model with an incorrectly high learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 1025.5645 - accuracy: 0.3944 - val_loss: 2.1251 - val_accuracy: 0.2286\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 4.8081 - accuracy: 0.2697 - val_loss: 2.5011 - val_accuracy: 0.2629\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.6155 - accuracy: 0.2837 - val_loss: 1.9929 - val_accuracy: 0.3161\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 3.1149 - accuracy: 0.2693 - val_loss: 2.2086 - val_accuracy: 0.2468\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.6198 - accuracy: 0.2700 - val_loss: 2.0240 - val_accuracy: 0.2921\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.6134 - accuracy: 0.3033 - val_loss: 3.0692 - val_accuracy: 0.3143\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.5199 - accuracy: 0.2944 - val_loss: 2.1608 - val_accuracy: 0.3264\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.4835 - accuracy: 0.2899 - val_loss: 2.2199 - val_accuracy: 0.3198\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.2313 - accuracy: 0.2900 - val_loss: 2.6217 - val_accuracy: 0.2418\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.4974 - accuracy: 0.2755 - val_loss: 2.3413 - val_accuracy: 0.3341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2abce99cd30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_images, train_labels), _ = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1.),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The same model with a more appropriate learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.3803 - accuracy: 0.9106 - val_loss: 0.1821 - val_accuracy: 0.9529\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1438 - accuracy: 0.9626 - val_loss: 0.1561 - val_accuracy: 0.9651\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.1171 - accuracy: 0.9729 - val_loss: 0.1736 - val_accuracy: 0.9683\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 0.0995 - accuracy: 0.9774 - val_loss: 0.2183 - val_accuracy: 0.9670\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0979 - accuracy: 0.9802 - val_loss: 0.2113 - val_accuracy: 0.9712\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0854 - accuracy: 0.9838 - val_loss: 0.2290 - val_accuracy: 0.9707\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 0.0706 - accuracy: 0.9867 - val_loss: 0.2757 - val_accuracy: 0.9732\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0734 - accuracy: 0.9870 - val_loss: 0.2716 - val_accuracy: 0.9730\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0680 - accuracy: 0.9887 - val_loss: 0.3296 - val_accuracy: 0.9709\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 0.0585 - accuracy: 0.9905 - val_loss: 0.3026 - val_accuracy: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2abcedb3ac0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-2),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          batch_size=128,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging better architecture priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Increasing model capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple logistic regression on MNIST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 961us/step - loss: 0.6673 - accuracy: 0.8369 - val_loss: 0.3591 - val_accuracy: 0.9031\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 0s 730us/step - loss: 0.3506 - accuracy: 0.9037 - val_loss: 0.3073 - val_accuracy: 0.9143\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.3152 - accuracy: 0.9119 - val_loss: 0.2907 - val_accuracy: 0.9193\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 0s 698us/step - loss: 0.2993 - accuracy: 0.9161 - val_loss: 0.2803 - val_accuracy: 0.9220\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.2895 - accuracy: 0.9191 - val_loss: 0.2770 - val_accuracy: 0.9215\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 0s 682us/step - loss: 0.2829 - accuracy: 0.9206 - val_loss: 0.2741 - val_accuracy: 0.9233\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 0s 672us/step - loss: 0.2781 - accuracy: 0.9222 - val_loss: 0.2694 - val_accuracy: 0.9259\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 0s 685us/step - loss: 0.2742 - accuracy: 0.9237 - val_loss: 0.2677 - val_accuracy: 0.9273\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 0s 672us/step - loss: 0.2713 - accuracy: 0.9242 - val_loss: 0.2655 - val_accuracy: 0.9277\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 0s 688us/step - loss: 0.2687 - accuracy: 0.9251 - val_loss: 0.2642 - val_accuracy: 0.9291\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 0s 722us/step - loss: 0.2661 - accuracy: 0.9261 - val_loss: 0.2647 - val_accuracy: 0.9287\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 0s 677us/step - loss: 0.2646 - accuracy: 0.9269 - val_loss: 0.2629 - val_accuracy: 0.9300\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 0s 674us/step - loss: 0.2632 - accuracy: 0.9275 - val_loss: 0.2621 - val_accuracy: 0.9293\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 0s 669us/step - loss: 0.2619 - accuracy: 0.9277 - val_loss: 0.2627 - val_accuracy: 0.9293\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 0s 677us/step - loss: 0.2603 - accuracy: 0.9282 - val_loss: 0.2621 - val_accuracy: 0.9296\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 0s 674us/step - loss: 0.2594 - accuracy: 0.9286 - val_loss: 0.2616 - val_accuracy: 0.9302\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 0s 680us/step - loss: 0.2580 - accuracy: 0.9293 - val_loss: 0.2602 - val_accuracy: 0.9308\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 0s 714us/step - loss: 0.2572 - accuracy: 0.9297 - val_loss: 0.2608 - val_accuracy: 0.9313\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 0s 714us/step - loss: 0.2562 - accuracy: 0.9293 - val_loss: 0.2627 - val_accuracy: 0.9305\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 0s 744us/step - loss: 0.2557 - accuracy: 0.9300 - val_loss: 0.2612 - val_accuracy: 0.9305\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([layers.Dense(10, activation=\"softmax\")])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_small_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2abdd351cd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "val_loss = history_small_model.history[\"val_loss\"]\n",
    "epochs = range(1, 21)\n",
    "plt.plot(epochs, val_loss, \"b--\",\n",
    "         label=\"Validation loss\")\n",
    "plt.title(\"Effect of insufficient model capacity on validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 0.3603 - accuracy: 0.8962 - val_loss: 0.1778 - val_accuracy: 0.9498\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9528 - val_loss: 0.1354 - val_accuracy: 0.9593\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.1111 - accuracy: 0.9673 - val_loss: 0.1153 - val_accuracy: 0.9665\n",
      "Epoch 4/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0867 - accuracy: 0.9738 - val_loss: 0.1015 - val_accuracy: 0.9707\n",
      "Epoch 5/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.9791 - val_loss: 0.0980 - val_accuracy: 0.9718\n",
      "Epoch 6/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9823 - val_loss: 0.0941 - val_accuracy: 0.9719\n",
      "Epoch 7/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0488 - accuracy: 0.9849 - val_loss: 0.0922 - val_accuracy: 0.9734\n",
      "Epoch 8/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0397 - accuracy: 0.9883 - val_loss: 0.1015 - val_accuracy: 0.9714\n",
      "Epoch 9/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9892 - val_loss: 0.0961 - val_accuracy: 0.9748\n",
      "Epoch 10/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9910 - val_loss: 0.1088 - val_accuracy: 0.9728\n",
      "Epoch 11/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9922 - val_loss: 0.1021 - val_accuracy: 0.9750\n",
      "Epoch 12/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.1088 - val_accuracy: 0.9736\n",
      "Epoch 13/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.1000 - val_accuracy: 0.9772\n",
      "Epoch 14/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.1061 - val_accuracy: 0.9772\n",
      "Epoch 15/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.1116 - val_accuracy: 0.9757\n",
      "Epoch 16/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.1162 - val_accuracy: 0.9762\n",
      "Epoch 17/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.1198 - val_accuracy: 0.9757\n",
      "Epoch 18/20\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.1251 - val_accuracy: 0.9765\n",
      "Epoch 19/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1272 - val_accuracy: 0.9760\n",
      "Epoch 20/20\n",
      "375/375 [==============================] - 0s 1ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.1455 - val_accuracy: 0.9762\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(96, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_large_model = model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Improving generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Dataset curation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Regularizing your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Reducing the network's size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Original model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.5229 - accuracy: 0.7689 - val_loss: 0.3902 - val_accuracy: 0.8685\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3072 - accuracy: 0.9006 - val_loss: 0.3035 - val_accuracy: 0.8877\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2225 - accuracy: 0.9269 - val_loss: 0.2767 - val_accuracy: 0.8922\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1764 - accuracy: 0.9421 - val_loss: 0.2833 - val_accuracy: 0.8864\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1478 - accuracy: 0.9523 - val_loss: 0.2791 - val_accuracy: 0.8889\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1193 - accuracy: 0.9621 - val_loss: 0.2905 - val_accuracy: 0.8873\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1009 - accuracy: 0.9697 - val_loss: 0.3218 - val_accuracy: 0.8813\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.0845 - accuracy: 0.9748 - val_loss: 0.3286 - val_accuracy: 0.8817\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0703 - accuracy: 0.9805 - val_loss: 0.3964 - val_accuracy: 0.8715\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0587 - accuracy: 0.9839 - val_loss: 0.3722 - val_accuracy: 0.8775\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0491 - accuracy: 0.9869 - val_loss: 0.4128 - val_accuracy: 0.8732\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.0395 - accuracy: 0.9907 - val_loss: 0.4257 - val_accuracy: 0.8748\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0323 - accuracy: 0.9928 - val_loss: 0.4597 - val_accuracy: 0.8740\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9936 - val_loss: 0.4940 - val_accuracy: 0.8708\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0191 - accuracy: 0.9969 - val_loss: 0.5736 - val_accuracy: 0.8624\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.0165 - accuracy: 0.9977 - val_loss: 0.5517 - val_accuracy: 0.8683\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.5847 - val_accuracy: 0.8673\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0117 - accuracy: 0.9983 - val_loss: 0.6141 - val_accuracy: 0.8665\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.6469 - val_accuracy: 0.8645\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.6779 - val_accuracy: 0.8654\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "(train_data, train_labels), _ = imdb.load_data(num_words=10000)\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "train_data = vectorize_sequences(train_data)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_original = model.fit(train_data, train_labels,\n",
    "                             epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Version of the model with lower capacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 14ms/step - loss: 0.6113 - accuracy: 0.6013 - val_loss: 0.5579 - val_accuracy: 0.7004\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5200 - accuracy: 0.7889 - val_loss: 0.5139 - val_accuracy: 0.7872\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4719 - accuracy: 0.8578 - val_loss: 0.4993 - val_accuracy: 0.7889\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.4372 - accuracy: 0.8940 - val_loss: 0.4729 - val_accuracy: 0.8394\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.4075 - accuracy: 0.9179 - val_loss: 0.4589 - val_accuracy: 0.8530\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.3784 - accuracy: 0.9371 - val_loss: 0.4320 - val_accuracy: 0.8764\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3387 - accuracy: 0.9533 - val_loss: 0.4127 - val_accuracy: 0.8661\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.2854 - accuracy: 0.9597 - val_loss: 0.3655 - val_accuracy: 0.8798\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.2261 - accuracy: 0.9669 - val_loss: 0.3242 - val_accuracy: 0.8870\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1776 - accuracy: 0.9714 - val_loss: 0.3093 - val_accuracy: 0.8875\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.1441 - accuracy: 0.9739 - val_loss: 0.3144 - val_accuracy: 0.8823\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.1216 - accuracy: 0.9772 - val_loss: 0.3202 - val_accuracy: 0.8811\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.1047 - accuracy: 0.9797 - val_loss: 0.3261 - val_accuracy: 0.8818\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0915 - accuracy: 0.9820 - val_loss: 0.3238 - val_accuracy: 0.8812\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0814 - accuracy: 0.9843 - val_loss: 0.3395 - val_accuracy: 0.8817\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 10ms/step - loss: 0.0727 - accuracy: 0.9863 - val_loss: 0.3501 - val_accuracy: 0.8805\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0655 - accuracy: 0.9881 - val_loss: 0.3630 - val_accuracy: 0.8790\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0588 - accuracy: 0.9896 - val_loss: 0.3922 - val_accuracy: 0.8760\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0544 - accuracy: 0.9901 - val_loss: 0.4000 - val_accuracy: 0.8762\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0485 - accuracy: 0.9918 - val_loss: 0.4115 - val_accuracy: 0.8754\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(4, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_smaller_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Version of the model with higher capacity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 2s 51ms/step - loss: 0.5445 - accuracy: 0.7473 - val_loss: 0.2976 - val_accuracy: 0.8856\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 44ms/step - loss: 0.2604 - accuracy: 0.8945 - val_loss: 0.2848 - val_accuracy: 0.8843\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 43ms/step - loss: 0.1480 - accuracy: 0.9450 - val_loss: 0.2844 - val_accuracy: 0.8936\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.0744 - accuracy: 0.9739 - val_loss: 0.3316 - val_accuracy: 0.8844\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.1011 - accuracy: 0.9782 - val_loss: 0.3291 - val_accuracy: 0.8831\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 0.0064 - accuracy: 0.9996 - val_loss: 0.4952 - val_accuracy: 0.8889\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 8.7057e-04 - accuracy: 0.9999 - val_loss: 0.5850 - val_accuracy: 0.8887\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 1.2557e-04 - accuracy: 1.0000 - val_loss: 0.7069 - val_accuracy: 0.8872\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 1.9380e-05 - accuracy: 1.0000 - val_loss: 0.8218 - val_accuracy: 0.8884\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 4.4646e-06 - accuracy: 1.0000 - val_loss: 0.9189 - val_accuracy: 0.8878\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 1.1404e-06 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.8877\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 3.5315e-07 - accuracy: 1.0000 - val_loss: 1.0941 - val_accuracy: 0.8870\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 1.2562e-07 - accuracy: 1.0000 - val_loss: 1.1469 - val_accuracy: 0.8875\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 5.4071e-08 - accuracy: 1.0000 - val_loss: 1.1801 - val_accuracy: 0.8865\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 3.0104e-08 - accuracy: 1.0000 - val_loss: 1.2230 - val_accuracy: 0.8880\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 2.0037e-08 - accuracy: 1.0000 - val_loss: 1.2432 - val_accuracy: 0.8876\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.4986e-08 - accuracy: 1.0000 - val_loss: 1.2621 - val_accuracy: 0.8879\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 1.2002e-08 - accuracy: 1.0000 - val_loss: 1.2739 - val_accuracy: 0.8874\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 42ms/step - loss: 9.9763e-09 - accuracy: 1.0000 - val_loss: 1.2840 - val_accuracy: 0.8877\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 8.5640e-09 - accuracy: 1.0000 - val_loss: 1.2935 - val_accuracy: 0.8875\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(512, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_larger_model = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Adding weight regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding L2 weight regularization to the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 15ms/step - loss: 0.5850 - accuracy: 0.8007 - val_loss: 0.4693 - val_accuracy: 0.8677\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3996 - accuracy: 0.8961 - val_loss: 0.4025 - val_accuracy: 0.8763\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3346 - accuracy: 0.9147 - val_loss: 0.3629 - val_accuracy: 0.8891\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3016 - accuracy: 0.9227 - val_loss: 0.3696 - val_accuracy: 0.8816\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2809 - accuracy: 0.9292 - val_loss: 0.3521 - val_accuracy: 0.8873\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2639 - accuracy: 0.9344 - val_loss: 0.3526 - val_accuracy: 0.8863\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2494 - accuracy: 0.9408 - val_loss: 0.3582 - val_accuracy: 0.8838\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2457 - accuracy: 0.9399 - val_loss: 0.3600 - val_accuracy: 0.8847\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2375 - accuracy: 0.9435 - val_loss: 0.3784 - val_accuracy: 0.8791\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2283 - accuracy: 0.9485 - val_loss: 0.3880 - val_accuracy: 0.8755\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2250 - accuracy: 0.9509 - val_loss: 0.3721 - val_accuracy: 0.8813\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2201 - accuracy: 0.9521 - val_loss: 0.3752 - val_accuracy: 0.8805\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2194 - accuracy: 0.9508 - val_loss: 0.3850 - val_accuracy: 0.8801\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2114 - accuracy: 0.9540 - val_loss: 0.4055 - val_accuracy: 0.8735\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2111 - accuracy: 0.9562 - val_loss: 0.4005 - val_accuracy: 0.8745\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2062 - accuracy: 0.9549 - val_loss: 0.4217 - val_accuracy: 0.8696\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2029 - accuracy: 0.9572 - val_loss: 0.3960 - val_accuracy: 0.8763\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2028 - accuracy: 0.9561 - val_loss: 0.4055 - val_accuracy: 0.8759\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2010 - accuracy: 0.9589 - val_loss: 0.4476 - val_accuracy: 0.8666\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.1953 - accuracy: 0.9613 - val_loss: 0.4087 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(16,\n",
    "                 kernel_regularizer=regularizers.l2(0.002),\n",
    "                 activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_l2_reg = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Different weight regularizers available in Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.regularizers.L1L2 at 0x2abde4e5bb0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "regularizers.l1(0.001)\n",
    "regularizers.l1_l2(l1=0.001, l2=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Adding dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding dropout to the IMDB model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 25ms/step - loss: 0.6432 - accuracy: 0.6165 - val_loss: 0.5380 - val_accuracy: 0.8469\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.5332 - accuracy: 0.7515 - val_loss: 0.4350 - val_accuracy: 0.8600\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.4508 - accuracy: 0.8064 - val_loss: 0.3514 - val_accuracy: 0.8852\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.3861 - accuracy: 0.8501 - val_loss: 0.3133 - val_accuracy: 0.8806\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.3309 - accuracy: 0.8781 - val_loss: 0.2894 - val_accuracy: 0.8881\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2896 - accuracy: 0.8978 - val_loss: 0.2773 - val_accuracy: 0.8929\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.2534 - accuracy: 0.9162 - val_loss: 0.2741 - val_accuracy: 0.8936\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.2277 - accuracy: 0.9273 - val_loss: 0.2812 - val_accuracy: 0.8918\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1974 - accuracy: 0.9383 - val_loss: 0.2902 - val_accuracy: 0.8907\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1792 - accuracy: 0.9462 - val_loss: 0.3074 - val_accuracy: 0.8896\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1620 - accuracy: 0.9494 - val_loss: 0.3268 - val_accuracy: 0.8879\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1398 - accuracy: 0.9565 - val_loss: 0.3638 - val_accuracy: 0.8875\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1282 - accuracy: 0.9625 - val_loss: 0.3811 - val_accuracy: 0.8872\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.1142 - accuracy: 0.9666 - val_loss: 0.4024 - val_accuracy: 0.8879\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.1045 - accuracy: 0.9683 - val_loss: 0.4244 - val_accuracy: 0.8865\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.1031 - accuracy: 0.9710 - val_loss: 0.4712 - val_accuracy: 0.8859\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0934 - accuracy: 0.9737 - val_loss: 0.4844 - val_accuracy: 0.8853\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 11ms/step - loss: 0.0860 - accuracy: 0.9771 - val_loss: 0.5246 - val_accuracy: 0.8831\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0829 - accuracy: 0.9773 - val_loss: 0.5545 - val_accuracy: 0.8842\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0806 - accuracy: 0.9786 - val_loss: 0.5792 - val_accuracy: 0.8830\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "history_dropout = model.fit(\n",
    "    train_data, train_labels,\n",
    "    epochs=20, batch_size=512, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter05_fundamentals-of-ml.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
